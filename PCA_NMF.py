# -*- coding: utf-8 -*-
"""71884

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FdIeTp-MgrR5iAK2USQlHpJ9xs6OISMO
"""

import numpy as np
import matplotlib.pyplot as plt
from keras.datasets import mnist
from mpl_toolkits import mplot3d

# print(x_train)

(x_train, y_train), (x_test, y_test) = mnist.load_data()
n = 20000
te = 4000
x_train = x_train[:n]/255
x_test = x_test[:te]
x_test = x_test.reshape(te,784)/255

"""PCA FOR M = 2"""

M = 2
x_pca = x_train.reshape(n,28*28,1)
x_pca = x_pca - np.mean(x_pca,axis=0)
S = np.mean([np.matmul(x.reshape(784,1),x.reshape(1,784))  for x in x_pca],axis=0)
# print(S[190])
eig_val,eig_vec = np.linalg.eig(S)
index = list(range(len(eig_val)))
index.sort(key = eig_val.__getitem__)
eig_val[:] = [eig_val[i] for i in index]
eig_vec[:] = [eig_vec[i] for i in index]


print(eig_vec[-M:].shape)
print(x_test.shape,y_test.shape)
x_test_pca = (x_test  - np.mean(x_test,axis=0))
x_hat=np.zeros((M,te))
x_hat=np.matmul(eig_vec[-M:],np.transpose(x_test_pca))
print(x_hat[0,:].shape)
plt.scatter(x_hat[0,:], x_hat[1,:], c=y_test[:te],  cmap='prism',alpha=0.9)
plt.legend()
plt.show()

"""# PCA for M = 3"""

M = 3
x_pca = x_train.reshape(n,28*28,1)
x_pca = x_pca - np.mean(x_pca,axis=0)
S = np.mean([np.matmul(x.reshape(784,1),x.reshape(1,784))  for x in x_pca],axis=0)
# print(S[190])
eig_val,eig_vec = np.linalg.eig(S)
index = list(range(len(eig_val)))
index.sort(key = eig_val.__getitem__)
eig_val[:] = [eig_val[i] for i in index]
eig_vec[:] = [eig_vec[i] for i in index]


print(eig_vec[-M:].shape)
print(x_test.shape,y_test.shape)
x_test_pca = (x_test  - np.mean(x_test,axis=0))
x_hat=np.zeros((M,te))
x_hat=np.matmul(eig_vec[-M:],np.transpose(x_test_pca))
print(x_hat[0,:].shape)
plt.scatter(x_hat[0,:], x_hat[1,:], c=y_test[:te],  cmap='prism',alpha=0.9)
plt.legend()
plt.show()

"""NMF"""

def NMF(x_nmf,k,n):
    epsW=np.ones((784,k))*0.00001
    epsH=np.ones((k,n))*0.00001
    W = np.random.random((784,k))
    H = np.random.random((k,n))
    threshold=0.01
    for i in range(100):
      num1 = np.matmul(np.transpose(W),np.transpose(x_nmf))+epsH
      den1 = np.matmul(np.matmul(np.transpose(W),W),H)+epsH

      num2 = np.matmul(np.transpose(x_nmf),np.transpose(H))+epsW
      den2 = np.matmul(W,np.matmul(H,np.transpose(H)))+epsW
      # print(num2.shape)
      # print(den2.shape)
      H = np.divide(np.multiply(H,num1),den1)
      W = np.divide(np.multiply(W,num2),den2)
      if np.sum(np.abs(np.transpose(x_nmf) - np.matmul(W,H)) )< threshold:
        print(i)
        break
    return W

def nmf_reconstruct(x,W,k):
    H = np.random.random((k,x.shape[0]))
    epsH = np.ones((k,x.shape[0]))*0.00001
    print(H.shape,epsH.shape,W.shape)
    num1 = np.matmul(np.transpose(W),np.transpose(x))+epsH
    den1 = np.matmul(np.matmul(np.transpose(W),W),H)+epsH
    H = np.divide(np.multiply(H,num1),den1)

    threshold=0.0001
    for iter in range(100):
      num1 = np.matmul(np.transpose(W),np.transpose(x))+epsH
      den1 = np.matmul(np.matmul(np.transpose(W),W),H)+epsH
      H = np.divide(np.multiply(H,num1),den1)
      
      if np.abs(np.sum(np.transpose(x)-np.matmul(W,H)) )< threshold:
          print(iter)
          print(np.abs(np.sum(np.transpose(x)-np.matmul(W,H))))
          break
    return H

print(x_test.shape)

"""# NMF for K=2"""

W = NMF(x_train.reshape(-1,784),2,n)
H = nmf_reconstruct(x_test,W,2)
recon=np.matmul(W,H)

print(recon.shape)
recon1 = recon.reshape((28,28,te))
fig, ax = plt.subplots(3,5, figsize=(10,7), subplot_kw={'xticks':(), 'yticks': ()})
ax = ax.ravel()
for i in range(15):
    pixels = recon1[:,:,i].reshape(28,28)
    ax[i].imshow(pixels, cmap='viridis')
    ax[i].set_title("Digit - " + str(y_test[i]))
plt.imshow(pixels, cmap='gray')
plt.show()

plt.scatter(H[0,:], H[1,:], c=y_test[:te],  cmap='prism',alpha=0.9)
plt.legend()
plt.show()

# NMF for K = 3

W = NMF(x_train.reshape(-1,784),3,n)
H = nmf_reconstruct(x_test,W,3)
recon=np.matmul(W,H)

print(recon.shape)
recon1 = recon.reshape((28,28,te))
fig, ax = plt.subplots(3,5, figsize=(10,7), subplot_kw={'xticks':(), 'yticks': ()})
ax = ax.ravel()
for i in range(15):
    pixels = recon1[:,:,i].reshape(28,28)
    ax[i].imshow(pixels, cmap='viridis')
    ax[i].set_title("Digit - " + str(y_test[i]))
plt.imshow(pixels, cmap='gray')
plt.show()

ax = plt.axes(projection='3d')
ax.scatter3D(H.T[:,0], H.T[:,1], H.T[:,2], c=y_test[:te],  cmap='prism', alpha=0.4)
plt.show()

sample=np.argsort(y_train[0:n])

samplen = sample#[[None] for _ in range(10)]
print(samplen)
count = np.zeros(10,dtype='int32')
for j in sample:
    count[y_train[j]] = count[y_train[j]] + 1
count1 = np.ndarray.copy(count)
print(count1)

for j in range(1,10):
    count[j] = count[j] + count[j-1]
print(count)
print(count1)

# print(samplen)

x_train0 = x_train[samplen[0:count[0]]]
y_train0 = y_train[samplen[0:count[0]]]

x_train1 = x_train[samplen[count[0]:count[1]]]
y_train1 = y_train[samplen[count[0]:count[1]]]

x_train2 = x_train[samplen[count[1]:count[2]]]
y_train2 = y_train[samplen[count[1]:count[2]]]

x_train3 = x_train[samplen[count[2]:count[3]]]
y_train3 = y_train[samplen[count[2]:count[3]]]

x_train4 = x_train[samplen[count[3]:count[4]]]
y_train4 = y_train[samplen[count[3]:count[4]]]

x_train5 = x_train[samplen[count[4]:count[5]]]
y_train5 = y_train[samplen[count[4]:count[5]]]

x_train6 = x_train[samplen[count[5]:count[6]]]
y_train6 = y_train[samplen[count[5]:count[6]]]

x_train7 = x_train[samplen[count[6]:count[7]]]
y_train7 = y_train[samplen[count[6]:count[7]]]

x_train8 = x_train[samplen[count[7]:count[8]]]
y_train8 = y_train[samplen[count[7]:count[8]]]

x_train9 = x_train[samplen[count[8]:count[9]]]
y_train9 = y_train[samplen[count[8]:count[9]]]

# print(y_train6)



print(x_train1.reshape(-1,784).shape,count1[1])
w0 = NMF(x_train0.reshape(-1,784),10,count1[0])
w1 = NMF(x_train1.reshape(-1,784),10,count1[1])
w2 = NMF(x_train2.reshape(-1,784),10,count1[2])
w3 = NMF(x_train3.reshape(-1,784),10,count1[3])
w4 = NMF(x_train4.reshape(-1,784),10,count1[4])
w5 = NMF(x_train5.reshape(-1,784),10,count1[5])
w6 = NMF(x_train6.reshape(-1,784),10,count1[6])
w7 = NMF(x_train7.reshape(-1,784),10,count1[7])
w8 = NMF(x_train8.reshape(-1,784),10,count1[8])
w9 = NMF(x_train9.reshape(-1,784),10,count1[9])
print(w0.shape)

print(w9.shape)

W_trained_dict = np.concatenate((w0,w1,w2,w3,w4,w5,w6,w7,w8,w9),axis=1)
print(W_trained_dict.shape)

H = nmf_reconstruct(x_test,W_trained_dict,100)

output=[]
for i in range(te):
  x0=np.sum(H[0:10,i:i+1])
  x1=np.sum(H[11:20,i:i+1])
  x2=np.sum(H[21:30,i:i+1])
  x3=np.sum(H[31:40,i:i+1])
  x4=np.sum(H[41:50,i:i+1])
  x5=np.sum(H[51:60,i:i+1])
  x6=np.sum(H[61:70,i:i+1])
  x7=np.sum(H[71:80,i:i+1])
  x8=np.sum(H[81:90,i:i+1])
  x9=np.sum(H[91:100,i:i+1])
  digit=np.argmax((x0,x1,x2,x3,x4,x5,x6,x7,x8,x9))
  output.append(digit)
output=np.asarray(output)
print(output)

import sklearn
from sklearn.metrics import confusion_matrix
cm = sklearn.metrics.confusion_matrix(y_test[:te], output)
print(cm)
accuracy=sklearn.metrics.accuracy_score(y_test[:te], output)
print(accuracy)

def EM(spectogram, iterations, components, custom, pfz):
    time = spectogram.shape[1]
    frequency = spectogram.shape[0]
    ptz = np.random.uniform(size=(time, components))
    pfz = np.random.uniform(size=(frequency, components))
    qtzf= np.zeros((frequency, time, components))

    Vft=spectogram # freq vs time


    for i in range(iterations):
        #E STEP
        sum=np.zeros((frequency, time))
        for z in range(components):
            qtzf[:,:,z] = np.matmul(np.expand_dims(pfz[:,z],axis=1),np.expand_dims(ptz[:,z],axis=0))
            sum += qtzf[:,:,z]
        for z in range(components):
            qtzf[:,:,z] = qtzf[:,:,z]/(sum + np.ones((sum.shape[0],sum.shape[1]))*0.00001)


        

        #M STEP
        #update ptz
        ptz = ((np.sum((Vft*qtzf.swapaxes(0,2).swapaxes(1,2)).swapaxes(1,2).swapaxes(0,2),axis=0)).swapaxes(0,1)/np.sum((Vft*qtzf.swapaxes(0,2).swapaxes(1,2)+np.ones((Vft.shape[0],Vft.shape[1]))*0.00001).swapaxes(1,2).swapaxes(0,2),axis=(0,2))).swapaxes(0,1)
        #update pfz
        if custom==0:
            pfz=np.sum((Vft*qtzf.swapaxes(0,2).swapaxes(1,2)).swapaxes(1,2).swapaxes(0,2),axis=1)/np.sum((Vft*qtzf.swapaxes(0,2).swapaxes(1,2)+np.ones((Vft.shape[0],Vft.shape[1]))*0.00001).swapaxes(1,2).swapaxes(0,2), axis=(0,1))
        

        # calculate likelihood
        sum1=np.zeros((frequency, time))
        for z in range(components):
            sum1+=qtzf[:,:,z]*np.log((np.matmul(np.expand_dims(pfz[:,z],axis=1),np.expand_dims(ptz[:,z],axis=0))+np.ones(qtzf[:,:,z].shape)*0.00001)/(qtzf[:,:,z]+np.ones(qtzf[:,:,z].shape)*0.00001))

        ll=np.sum( Vft*sum1,axis=(0,1) )
        print(ll)

    return ptz, pfz

X=np.reshape(x_train,(n, 784))
red_dim = EM(X.T,30,2,custom=0,pfz=None)

print(red_dim[0].shape)
print(red_dim[1].shape)
q=red_dim[0]
plt.scatter(q[:,0], q[:,1], c=y_train,  cmap='prism', alpha=0.4)
plt.show()